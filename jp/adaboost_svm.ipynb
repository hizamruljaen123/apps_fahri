{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load data from Excel file\n",
    "data_path = '../data_latih.xlsx'\n",
    "data_latih = pd.read_excel(data_path)\n",
    "\n",
    "# Encoding data kategorikal\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode 'L/P'\n",
    "data_latih['L/P'] = le.fit_transform(data_latih['L/P'])\n",
    "\n",
    "# Encode 'Penghasilan'\n",
    "penghasilan_mapping = {\n",
    "    'Rp. 500,000 - Rp. 999,999': 0,\n",
    "    'Rp. 1,000,000 - Rp. 1,999,999': 1,\n",
    "    'Rp. 2,000,000 - Rp. 4,999,999': 2,\n",
    "    'Tidak Berpenghasilan': 3,\n",
    "    'Kurang dari Rp. 500,000': 4\n",
    "}\n",
    "data_latih['Penghasilan'] = data_latih['Penghasilan'].map(penghasilan_mapping)\n",
    "\n",
    "# Encode 'Status Ekonomi'\n",
    "status_ekonomi_mapping = {\n",
    "    'SANGAT MISKIN': 0,\n",
    "    'MISKIN': 1,\n",
    "    'CUKUP': 2\n",
    "}\n",
    "data_latih['Status Ekonomi'] = data_latih['Status Ekonomi'].map(status_ekonomi_mapping)\n",
    "\n",
    "# Encode 'Layak PIP'\n",
    "layak_pip_mapping = {'Ya': 1, 'Tidak': 0}\n",
    "data_latih['Layak PIP'] = data_latih['Layak PIP'].map(layak_pip_mapping)\n",
    "# Drop columns that are not used in the model\n",
    "data_latih = data_latih.drop(columns=['Nama', 'Alasan Layak PIP', 'Status Bantuan', 'Status Kesesuaian'])\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "X = data_latih.drop(columns=['Layak PIP'])\n",
    "y = data_latih['Layak PIP']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menampilkan shapes dari training dan testing set\n",
    "print(\"Training set shape:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Testing set shape:\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalisasi kolom numerik\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "# Display the first few rows of the scaled data\n",
    "print(\"First few rows of X_train_scaled:\")\n",
    "display(X_train_scaled.head())\n",
    "print(\"First few rows of X_test_scaled:\")\n",
    "display(X_test_scaled.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi parameter\n",
    "\n",
    "# Bobot awal diinisialisasi dengan nilai nol untuk semua fitur\n",
    "w = np.zeros(X_train_scaled.shape[1])\n",
    "\n",
    "# Bias awal diinisialisasi dengan nilai nol\n",
    "b = 0\n",
    "\n",
    "# Learning rate (alpha) menentukan seberapa besar langkah yang diambil pada setiap iterasi saat memperbarui bobot dan bias\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Jumlah iterasi menentukan berapa kali proses pembaruan bobot dan bias dilakukan\n",
    "n_iterations = 1000\n",
    "\n",
    "# Menampilkan parameter awal\n",
    "print(\"Initial weights (w):\", w)\n",
    "print(\"Initial bias (b):\", b)\n",
    "print(\"Learning rate:\", learning_rate)\n",
    "print(\"Number of iterations:\", n_iterations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghitung hinge loss\n",
    "def hinge_loss(X, y, w, b):\n",
    "    # Hinge loss dihitung dengan maks(0, 1 - y * (X * w + b))\n",
    "    return np.maximum(0, 1 - y * (np.dot(X, w) + b))\n",
    "\n",
    "# Menghitung hinge loss untuk parameter awal\n",
    "X_train_array = X_train_scaled.to_numpy()\n",
    "y_train_array = y_train.to_numpy()\n",
    "\n",
    "initial_loss = hinge_loss(X_train_array, y_train_array, w, b)\n",
    "print(\"Initial hinge loss:\", initial_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w, b, learning_rate, n_iterations):\n",
    "    # Melakukan iterasi sebanyak n_iterations\n",
    "    for iteration in range(n_iterations):\n",
    "        # Iterasi melalui setiap sampel data\n",
    "        for idx, x_i in enumerate(X):\n",
    "            # Menghitung kondisi apakah sampel terklasifikasi dengan benar (margin >= 1)\n",
    "            if y[idx] * (np.dot(x_i, w) + b) >= 1:\n",
    "                # Jika terklasifikasi dengan benar, hanya terapkan regularisasi pada bobot\n",
    "                w -= learning_rate * (2 * 1/n_iterations * w)\n",
    "            else:\n",
    "                # Jika terklasifikasi salah, perbarui bobot dan bias untuk mengurangi kesalahan\n",
    "                w -= learning_rate * (2 * 1/n_iterations * w - np.dot(x_i, y[idx] * x_i))\n",
    "                b -= learning_rate * y[idx]\n",
    "        \n",
    "        # Cetak bobot dan bias pada setiap iterasi\n",
    "        print(f\"Iteration {iteration + 1}/{n_iterations}:\")\n",
    "        print(f\"Weights: {w}\")\n",
    "        print(f\"Bias: {b}\\n\")\n",
    "    \n",
    "    # Mengembalikan bobot dan bias yang telah diperbarui\n",
    "    return w, b\n",
    "\n",
    "# Inisialisasi parameter\n",
    "w = np.zeros(X_train_scaled.shape[1])  # Bobot awal diinisialisasi dengan nilai nol untuk semua fitur\n",
    "b = 0  # Bias awal diinisialisasi dengan nilai nol\n",
    "learning_rate = 0.01  # Learning rate menentukan seberapa besar langkah yang diambil pada setiap iterasi\n",
    "n_iterations = 100  # Jumlah iterasi menentukan berapa kali proses pembaruan bobot dan bias dilakukan (gunakan 10 untuk mencetak lebih sedikit iterasi)\n",
    "\n",
    "# Melakukan gradient descent untuk memperbarui bobot dan bias\n",
    "w, b = gradient_descent(X_train_scaled.to_numpy(), y_train.to_numpy(), w, b, learning_rate, n_iterations)\n",
    "\n",
    "# Menampilkan parameter setelah pelatihan\n",
    "print(\"Trained weights (w):\", w)\n",
    "print(\"Trained bias (b):\", b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan prediksi menggunakan model SVM yang telah dilatih\n",
    "def predict(X, w, b):\n",
    "    return np.sign(np.dot(X, w) + b)\n",
    "# Melakukan prediksi pada data uji\n",
    "y_pred = predict(X_test_scaled.to_numpy(), w, b)\n",
    "\n",
    "# Menghitung akurasi model\n",
    "accuracy = np.mean(y_pred == y_test.to_numpy())\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan prediksi pada data latih\n",
    "y_train_pred = predict(X_train_scaled.to_numpy(), w, b)\n",
    "\n",
    "# Menghitung akurasi model pada data latih\n",
    "train_accuracy = np.mean(y_train_pred == y_train.to_numpy())\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Simpan bobot (weights) dan bias model ke file\n",
    "model_path = 'svm_model.pkl'\n",
    "joblib.dump((w, b), model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Muat bobot (weights) dan bias model dari file\n",
    "w_loaded, b_loaded = joblib.load(model_path)\n",
    "\n",
    "print(\"Model loaded:\")\n",
    "print(f\"Weights: {w_loaded}\")\n",
    "print(f\"Bias: {b_loaded}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muat data uji dari file Excel\n",
    "data_uji_path = '../data_uji.xlsx'\n",
    "data_uji = pd.read_excel(data_uji_path)\n",
    "\n",
    "# Tampilkan beberapa baris pertama dari data uji\n",
    "display(data_uji.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan prediksi menggunakan model SVM yang telah dilatih\n",
    "def predict(X, w, b):\n",
    "    return np.sign(np.dot(X, w) + b)\n",
    "\n",
    "# Normalisasi data uji (asumsi kolom yang digunakan sama dengan data latih)\n",
    "X_uji = data_uji.drop(columns=['Layak PIP'])\n",
    "scaler = StandardScaler()\n",
    "X_uji_scaled = scaler.fit_transform(X_uji)\n",
    "\n",
    "# Lakukan prediksi pada data uji\n",
    "y_pred_uji = predict(X_uji_scaled, w_loaded, b_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi hasil prediksi ke status kelayakan\n",
    "status_kelayakan = pd.Series(y_pred_uji).map({1: 'Sesuai', -1: 'Tidak Layak'})\n",
    "\n",
    "# Jika prediksi berbeda dengan keterangan \"Layak PIP\", berikan status \"Tidak Tepat Sasaran\"\n",
    "data_uji['Prediksi'] = status_kelayakan\n",
    "data_uji['Status Kelayakan'] = data_uji.apply(\n",
    "    lambda row: 'Sesuai' if row['Prediksi'] == 'Sesuai' and row['Layak PIP'] == 1 else\n",
    "                'Tidak Layak' if row['Prediksi'] == 'Tidak Layak' and row['Layak PIP'] == 0 else\n",
    "                'Tidak Tepat Sasaran', axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan hasil prediksi dan keterangan sebenarnya\n",
    "comparison = data_uji[['Layak PIP', 'Prediksi', 'Status Kelayakan']]\n",
    "\n",
    "# Tampilkan perbandingan\n",
    "display(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung jumlah yang sesuai atau tidak sesuai\n",
    "jumlah_sesuai = data_uji['Status Kelayakan'].value_counts().get('Sesuai', 0)\n",
    "jumlah_tidak_layak = data_uji['Status Kelayakan'].value_counts().get('Tidak Layak', 0)\n",
    "jumlah_tidak_tepat_sasaran = data_uji['Status Kelayakan'].value_counts().get('Tidak Tepat Sasaran', 0)\n",
    "\n",
    "print(f\"Jumlah Sesuai: {jumlah_sesuai}\")\n",
    "print(f\"Jumlah Tidak Layak: {jumlah_tidak_layak}\")\n",
    "print(f\"Jumlah Tidak Tepat Sasaran: {jumlah_tidak_tepat_sasaran}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Inisialisasi model SVM Linier\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Melatih model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Simpan model SVM Linier ke file\n",
    "svm_model_path = 'svm_model_no_adaBoost.pkl'\n",
    "joblib.dump(svm_model, svm_model_path)\n",
    "print(f\"Model SVM Linier disimpan ke {svm_model_path}\")\n",
    "\n",
    "# Melakukan prediksi pada data uji\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Menghitung akurasi model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f'Accuracy SVM Linier: {accuracy_svm}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Inisialisasi model AdaBoost dengan base estimator SVM\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=SVC(kernel='linear', probability=True), n_estimators=50, random_state=42)\n",
    "\n",
    "# Melatih model\n",
    "adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Simpan model SVM dengan AdaBoost ke file\n",
    "adaboost_model_path = 'adaboost_svm_model.pkl'\n",
    "joblib.dump(adaboost_model, adaboost_model_path)\n",
    "print(f\"Model SVM dengan AdaBoost disimpan ke {adaboost_model_path}\")\n",
    "\n",
    "# Melakukan prediksi pada data uji\n",
    "y_pred_adaboost = adaboost_model.predict(X_test_scaled)\n",
    "\n",
    "# Menghitung akurasi model\n",
    "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
    "print(f'Accuracy SVM dengan AdaBoost: {accuracy_adaboost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Confusion matrix dan laporan klasifikasi untuk SVM Linier\n",
    "print(\"Confusion Matrix - SVM Linier\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report - SVM Linier\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Confusion matrix dan laporan klasifikasi untuk SVM dengan AdaBoost\n",
    "print(\"Confusion Matrix - SVM dengan AdaBoost\")\n",
    "print(confusion_matrix(y_test, y_pred_adaboost))\n",
    "print(\"\\nClassification Report - SVM dengan AdaBoost\")\n",
    "print(classification_report(y_test, y_pred_adaboost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Langkah 1: Muat dan siapkan data latih\n",
    "data_latih_path = '../data_latih.xlsx'\n",
    "data_latih = pd.read_excel(data_latih_path)\n",
    "\n",
    "# Encoding data kategorikal\n",
    "le = LabelEncoder()\n",
    "data_latih['L/P'] = le.fit_transform(data_latih['L/P'])\n",
    "penghasilan_mapping = {\n",
    "    'Rp. 500,000 - Rp. 999,999': 0,\n",
    "    'Rp. 1,000,000 - Rp. 1,999,999': 1,\n",
    "    'Rp. 2,000,000 - Rp. 4,999,999': 2,\n",
    "    'Tidak Berpenghasilan': 3,\n",
    "    'Kurang dari Rp. 500,000': 4\n",
    "}\n",
    "data_latih['Penghasilan'] = data_latih['Penghasilan'].map(penghasilan_mapping)\n",
    "status_ekonomi_mapping = {\n",
    "    'SANGAT MISKIN': 0,\n",
    "    'MISKIN': 1,\n",
    "    'CUKUP': 2\n",
    "}\n",
    "data_latih['Status Ekonomi'] = data_latih['Status Ekonomi'].map(status_ekonomi_mapping)\n",
    "layak_pip_mapping = {'Ya': 1, 'Tidak': 0}\n",
    "data_latih['Layak PIP'] = data_latih['Layak PIP'].map(layak_pip_mapping)\n",
    "\n",
    "# Drop kolom yang tidak digunakan\n",
    "data_latih = data_latih.drop(columns=['Nama', 'Alasan Layak PIP', 'Status Bantuan', 'Status Kesesuaian'])\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "X = data_latih.drop(columns=['Layak PIP'])\n",
    "y = data_latih['Layak PIP']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisasi data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Langkah 2: Melatih model Decision Tree dan model Decision Tree dengan AdaBoost\n",
    "tree_model = DecisionTreeClassifier()\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=tree_model, n_estimators=50, algorithm='SAMME')\n",
    "\n",
    "# Melatih model\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Simpan model ke file\n",
    "joblib.dump(tree_model, 'tree_model.pkl')\n",
    "joblib.dump(adaboost_model, 'adaboost_tree_model.pkl')\n",
    "\n",
    "# Langkah 3: Muat model dari file\n",
    "tree_model = joblib.load('tree_model.pkl')\n",
    "adaboost_model = joblib.load('adaboost_tree_model.pkl')\n",
    "\n",
    "# Muat data uji dari file Excel\n",
    "data_uji_path = '../data_uji.xlsx'\n",
    "data_uji = pd.read_excel(data_uji_path)\n",
    "\n",
    "# Normalisasi data uji (asumsi kolom yang digunakan sama dengan data latih)\n",
    "X_uji = data_uji.drop(columns=['Layak PIP'])\n",
    "X_uji_scaled = scaler.transform(X_uji)\n",
    "\n",
    "# Target data uji\n",
    "y_uji = data_uji['Layak PIP']\n",
    "\n",
    "# Lakukan prediksi pada data uji menggunakan Decision Tree\n",
    "y_pred_tree = tree_model.predict(X_uji_scaled)\n",
    "\n",
    "# Lakukan prediksi pada data uji menggunakan Decision Tree dengan AdaBoost\n",
    "y_pred_adaboost = adaboost_model.predict(X_uji_scaled)\n",
    "\n",
    "# Menghitung akurasi model\n",
    "accuracy_tree = accuracy_score(y_uji, y_pred_tree)\n",
    "accuracy_adaboost = accuracy_score(y_uji, y_pred_adaboost)\n",
    "\n",
    "# Membuat DataFrame untuk menampilkan hasil akurasi\n",
    "accuracy_df = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Decision Tree dengan AdaBoost'],\n",
    "    'Accuracy': [accuracy_tree, accuracy_adaboost]\n",
    "})\n",
    "\n",
    "# Membuat DataFrame untuk confusion matrix\n",
    "confusion_matrix_tree = confusion_matrix(y_uji, y_pred_tree)\n",
    "confusion_matrix_adaboost = confusion_matrix(y_uji, y_pred_adaboost)\n",
    "\n",
    "confusion_df_tree = pd.DataFrame(confusion_matrix_tree, columns=['Predicted 0', 'Predicted 1'], index=['Actual 0', 'Actual 1'])\n",
    "confusion_df_adaboost = pd.DataFrame(confusion_matrix_adaboost, columns=['Predicted 0', 'Predicted 1'], index=['Actual 0', 'Actual 1'])\n",
    "\n",
    "# Membuat DataFrame untuk laporan klasifikasi\n",
    "classification_report_tree = classification_report(y_uji, y_pred_tree, output_dict=True)\n",
    "classification_report_adaboost = classification_report(y_uji, y_pred_adaboost, output_dict=True)\n",
    "\n",
    "classification_df_tree = pd.DataFrame(classification_report_tree).transpose()\n",
    "classification_df_adaboost = pd.DataFrame(classification_report_adaboost).transpose()\n",
    "\n",
    "# Menampilkan hasil dalam bentuk tabel\n",
    "print(\"Accuracy Comparison:\")\n",
    "display(accuracy_df)\n",
    "\n",
    "print(\"\\nConfusion Matrix - Decision Tree:\")\n",
    "display(confusion_df_tree)\n",
    "\n",
    "print(\"\\nConfusion Matrix - Decision Tree dengan AdaBoost:\")\n",
    "display(confusion_df_adaboost)\n",
    "\n",
    "print(\"\\nClassification Report - Decision Tree:\")\n",
    "display(classification_df_tree)\n",
    "\n",
    "print(\"\\nClassification Report - Decision Tree dengan AdaBoost:\")\n",
    "display(classification_df_adaboost)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
